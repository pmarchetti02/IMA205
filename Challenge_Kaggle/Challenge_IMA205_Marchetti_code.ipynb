{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMA205 Challenge 2024 : Classify dermoscopic images among 8 different diagnostic classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndi\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn_relief import ReliefF\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from skimage import measure\n",
    "from skimage.measure import regionprops\n",
    "from skimage import morphology\n",
    "from skimage import exposure\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.stats import gaussian_kde\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.metrics import MeanIoU\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta data\n",
    "meta_data_train = pd.read_csv('./ima205-challenge-2024/metadataTrain.csv')\n",
    "meta_data_test = pd.read_csv('./ima205-challenge-2024/metadataTest.csv')\n",
    "\n",
    "print('Meta data train:\\n', meta_data_train)\n",
    "print('Meta data test:\\n', meta_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to see some particular column in the meta data \n",
    "meta_data_train['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract images from Test and Train folders so that they match.\n",
    "train_images = []\n",
    "train_images_segmented = []\n",
    "test_images = []\n",
    "test_images_segmented = []\n",
    "\n",
    "path_train = \"./ima205-challenge-2024/Train/Train/\"\n",
    "path_test = \"./ima205-challenge-2024/Test/Test/\"\n",
    "\n",
    "# Extract segmented images from the Train and Test folder and match them with the non-segmented images\n",
    "content_train = os.listdir(path_train)\n",
    "for i in range(len(content_train)):\n",
    "\n",
    "  if content_train[i].lower().endswith(\".png\"):\n",
    "    if content_train[i].strip(\"_seg.png\") + \".jpg\" in content_train:\n",
    "      train_images_segmented.append(content_train[i])\n",
    "      train_images.append(content_train[i-1])\n",
    "\n",
    "content_test = os.listdir(path_test)\n",
    "for i in range(len(content_test)):\n",
    "\n",
    "  if content_test[i].lower().endswith(\".png\"):\n",
    "    if content_test[i].strip(\"_seg.png\") + \".jpg\" in content_test:\n",
    "      test_images_segmented.append(content_test[i])\n",
    "      test_images.append(content_test[i-1])\n",
    "\n",
    "print('Train images:\\n', train_images)\n",
    "print('Train images segmented:\\n', train_images_segmented)\n",
    "\n",
    "# Extract non-segmented images from the Train and Test folder\n",
    "train_images_full = []\n",
    "test_images_full = []\n",
    "     \n",
    "for i in range(len(content_train)):\n",
    "  if content_train[i].lower().endswith(\".jpg\"):\n",
    "    train_images_full.append(content_train[i])\n",
    "\n",
    "for i in range(len(content_test)):\n",
    "  if content_test[i].lower().endswith(\".jpg\"):\n",
    "    test_images_full.append(content_test[i])\n",
    "\n",
    "print('Train images full:\\n', train_images_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute classes weights\n",
    "class_weights = {}\n",
    "for i in range(1, 9):\n",
    "  class_weights[i] = len(meta_data_train[meta_data_train['CLASS'] == i]) / len(meta_data_train)\n",
    "\n",
    "print('Class weights:\\n', class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Method 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dullRazor(image):\n",
    "    grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY )\n",
    "\n",
    "    #Black hat filter\n",
    "    kernel = cv2.getStructuringElement(1,(9,9)) \n",
    "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    bhg = cv2.GaussianBlur(blackhat,(3,3),cv2.BORDER_DEFAULT)\n",
    "    \n",
    "    _,mask = cv2.threshold(bhg,10,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    #Replace pixels of the mask\n",
    "    dst = cv2.inpaint(image,mask,6,cv2.INPAINT_TELEA)   \n",
    "\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_img(img, threshold=120):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Get the coordinates of the pixels in the diagonal\n",
    "    y_coords = ([i for i in range(0, h, 3)], [i for i in range(h - 3, -1, -3)])\n",
    "    x_coords = ([i for i in range(0, w, 4)], [i for i in range(0, w, 4)])\n",
    "\n",
    "    # Get the mean value of the pixels in the diagonal, form 0,0 to h,w and from h,0 to 0,w\n",
    "    coordinates = {'y1_1': 0, 'x1_1': 0, 'y2_1': h, 'x2_1': w, 'y1_2': h, 'x1_2': 0, 'y2_2': 0, 'x2_2': w}\n",
    "    for i in range(2):\n",
    "        d = []\n",
    "        for y, x in zip(y_coords[i], x_coords[i]):\n",
    "            d.append(np.mean(img[y, x, :]))\n",
    "\n",
    "        # Get the location of the first point where the threshold is crossed\n",
    "        for idx, value in enumerate(d):\n",
    "            if value >= threshold:\n",
    "                coordinates['y1_' + str(i + 1)] = y_coords[i][idx]\n",
    "                coordinates['x1_' + str(i + 1)] = x_coords[i][idx]\n",
    "                break\n",
    "\n",
    "        # Get the location of the last point where the threshold is crossed\n",
    "        for idx, value in enumerate(reversed(d)):\n",
    "            if value >= threshold:\n",
    "                coordinates['y2_' + str(i + 1)] = y_coords[i][-idx if idx != 0 else -1]\n",
    "                coordinates['x2_' + str(i + 1)] = x_coords[i][-idx if idx != 0 else -1]\n",
    "                break\n",
    "\n",
    "    # Set the coordinates to crop the image\n",
    "    y1 = max(coordinates['y1_1'], coordinates['y2_2'])\n",
    "    y2 = min(coordinates['y2_1'], coordinates['y1_2'])\n",
    "    x1 = max(coordinates['x1_1'], coordinates['x1_2'])\n",
    "    x2 = min(coordinates['x2_1'], coordinates['x2_2'])\n",
    "\n",
    "    if img[y1:y2, x1:x2, :].shape[0] < 20 or img[y1:y2, x1:x2, :].shape[1] < 20:\n",
    "        return 0, h, 0, w, img\n",
    "    \n",
    "    return y1, y2, x1, x2, img[y1:y2, x1:x2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img_data):\n",
    "    try:\n",
    "        # Crop the image to get the region of interest\n",
    "        y1, y2, x1, x2, cropped_image = crop_img(img_data['original_image'])\n",
    "        img_data['roi_coords'] = {'y1': y1, 'y2': y2, 'x1': x1, 'x2': x2}\n",
    "        img_data['roi'] = cropped_image\n",
    "\n",
    "        img_data['roi'] = dullRazor(img_data['roi'])\n",
    "\n",
    "    except:\n",
    "        img_data['roi_coords'] = {'y1': 0, 'y2': img_data['original_image'].shape[0], 'x1': 0, 'x2': img_data['original_image'].shape[1]}\n",
    "        img_data['roi'] = img_data['original_image']\n",
    "\n",
    "        img_data['roi'] = dullRazor(img_data['roi'])\n",
    "\n",
    "    gray_image = cv2.cvtColor(img_data['roi'], cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img_data['roi'] = clahe.apply(gray_image)\n",
    "\n",
    "    # Apply median filtering\n",
    "    img_data['roi'] = cv2.medianBlur(img_data['roi'], 5)\n",
    "\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation (Otsu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image segmentation\n",
    "def segmentation(img_data):\n",
    "    # otsu\n",
    "    otsu_th, predicted_mask = cv2.threshold(img_data['roi'], 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    img_data['otsu_th'] = otsu_th\n",
    "    img_data['mask_thresholding'] = predicted_mask\n",
    "\n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_original_mask_shape(original_shape, mask, roi_coords):\n",
    "    original_mask = np.zeros(original_shape)\n",
    "\n",
    "    for i, y in enumerate(range(roi_coords['y1'], roi_coords['y2'])):\n",
    "        for j, x in enumerate(range(roi_coords['x1'], roi_coords['x2'])):\n",
    "            original_mask[y, x] = mask[i, j]\n",
    "\n",
    "    return original_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(img_data):\n",
    "    img_data['mask_thresholding'] = morphology.remove_small_holes(img_data['mask_thresholding'])\n",
    "\n",
    "    image = morphology.remove_small_objects(img_data['mask_thresholding'], min_size=3500)\n",
    "\n",
    "    if image.sum() == 0:\n",
    "        img_data['mask_thresholding'] = morphology.remove_small_objects(img_data['mask_thresholding'], min_size=1000)\n",
    "    else:\n",
    "        img_data['mask_thresholding'] = image\n",
    "    \n",
    "    img_data['mask_thresholding'] = morphology.opening(img_data['mask_thresholding'], morphology.disk(12))\n",
    "    img_data['mask_thresholding'] = morphology.dilation(img_data['mask_thresholding'], morphology.disk(12))\n",
    "\n",
    "    img_data['mask_thresholding'] = morphology.convex_hull_image(img_data['mask_thresholding'], offset_coordinates=True)\n",
    "\n",
    "    # Recover the original shape of the mask to match with image\n",
    "    img_data['mask'] = recover_original_mask_shape(img_data['img_shape'], img_data['mask_thresholding'], img_data['roi_coords'])\n",
    "    \n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skin_lesion_segmentation(img_root):\n",
    "    # Load the image\n",
    "    image = cv2.imread(img_root)\n",
    "\n",
    "    # Dictionary to store the image and all the relevant information\n",
    "    img_data = {}\n",
    "    img_data['original_image'] = image\n",
    "    img_data['img_shape'] = image.shape[:2]\n",
    "\n",
    "    # Process the image\n",
    "    img_data = preprocessing(img_data)\n",
    "    img_data = segmentation(img_data)\n",
    "    img_data = postprocessing(img_data)\n",
    "\n",
    "    predicted_mask = img_data['mask']\n",
    "\n",
    "    return predicted_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "for i in range(20,30):\n",
    "    image = cv2.imread(path_train + train_images_full[i])\n",
    "    mask = skin_lesion_segmentation(path_train + train_images_full[i])\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(image)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Method 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dullRazor(image):\n",
    "    grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY )\n",
    "\n",
    "    #Black hat filter\n",
    "    kernel = cv2.getStructuringElement(1,(9,9)) \n",
    "    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n",
    "\n",
    "    bhg = cv2.GaussianBlur(blackhat,(3,3),cv2.BORDER_DEFAULT)\n",
    "    \n",
    "    _,mask = cv2.threshold(bhg,10,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    #Replace pixels of the mask\n",
    "    dst = cv2.inpaint(image,mask,6,cv2.INPAINT_TELEA)   \n",
    "\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image):\n",
    "\n",
    "    image = dullRazor(image)\n",
    "\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    image = clahe.apply(gray_image)\n",
    "\n",
    "    # Apply median filtering\n",
    "    image = cv2.medianBlur(image, 5)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation (U-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and masks as numpy arrays\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(len(train_images)):\n",
    "    img = cv2.imread(path_train + train_images[i])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mask = cv2.imread(path_train + train_images_segmented[i])\n",
    "\n",
    "    # Preprocess the images and masks\n",
    "    img = preprocessing(img)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.reshape(img, (224, 224, 1))\n",
    "    img = img / 255.0\n",
    "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    mask = cv2.resize(mask, (224, 224))\n",
    "    mask = np.reshape(mask, (224, 224, 1))\n",
    "    mask = mask / 255.0\n",
    "\n",
    "    X.append(img)\n",
    "    Y.append(mask)\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Shuffle the training data\n",
    "X_train, y_train = random.shuffle(X_train, y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net model\n",
    "def unet(input_size = (224,224,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the U-Net model\n",
    "model = unet()\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, batch_size=16, epochs=3, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract non segmented images from Test and Train folders\n",
    "non_segmented_train_images = []\n",
    "non_segmented_test_images = []\n",
    "\n",
    "# Extract segmented images from the Train and Test folder and match them with the non-segmented images\n",
    "content_train = os.listdir(path_train)\n",
    "for i in range(len(content_train)):\n",
    "\n",
    "  if content_train[i].lower().endswith(\".png\"):\n",
    "    if not (content_train[i].strip(\"_seg.png\") + \".jpg\" in content_train):\n",
    "        non_segmented_train_images.append(content_train[i])\n",
    "\n",
    "content_test = os.listdir(path_test)\n",
    "for i in range(len(content_test)):\n",
    "\n",
    "  if content_test[i].lower().endswith(\".png\"):\n",
    "    if not (content_test[i].strip(\"_seg.png\") + \".jpg\" in content_test):\n",
    "        non_segmented_test_images.append(content_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "X = []\n",
    "for i in range(len(non_segmented_train_images)):\n",
    "    img = non_segmented_train_images[i]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Preprocess the images and masks (e.g., resizing, normalization)\n",
    "    img = preprocessing(img)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.reshape(img, (224, 224, 1))\n",
    "    img = img / 255.0\n",
    "\n",
    "    X.append(img)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# Make predictions\n",
    "predictions_train = model.predict(X)\n",
    "\n",
    "# Display the first image and its predicted mask\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X[0].reshape(224, 224), cmap='gray')\n",
    "plt.title(\"Image\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(predictions_train[0].reshape(224, 224), cmap='gray')\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "X = []\n",
    "for i in range(len(non_segmented_test_images)):\n",
    "    img = non_segmented_test_images[i]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Preprocess the images and masks (e.g., resizing, normalization)\n",
    "    img = preprocessing(img)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.reshape(img, (224, 224, 1))\n",
    "    img = img / 255.0\n",
    "\n",
    "    X.append(img)\n",
    "\n",
    "X = np.array(X)\n",
    "\n",
    "# Make predictions\n",
    "predictions_test = model.predict(X)\n",
    "\n",
    "# Display the first image and its predicted mask\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X[0].reshape(224, 224), cmap='gray')\n",
    "plt.title(\"Image\")\n",
    "plt.subplot(122)\n",
    "plt.imshow(predictions_test[0].reshape(224, 224), cmap='gray')\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(mask):\n",
    "\n",
    "    # Turn to binary mask\n",
    "    mask = np.where(mask > 0.35, 1, 0)\n",
    "    \n",
    "    mask = morphology.remove_small_holes(mask)\n",
    "\n",
    "    mask = morphology.remove_small_objects(mask, min_size=3500)\n",
    "\n",
    "    if mask.sum() == 0:\n",
    "        mask = morphology.remove_small_objects(mask, min_size=1000)\n",
    "    else:\n",
    "        mask = mask\n",
    "    \n",
    "    mask = morphology.opening(mask, morphology.disk(12))\n",
    "    mask = morphology.dilation(mask, morphology.disk(12))\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute asymmetry features\n",
    "def compute_asymmetry_features(image, mask):\n",
    "    # Find the center of mass of the lesion\n",
    "    props = regionprops(mask)[0]\n",
    "    center_y = int(props.centroid[0])\n",
    "    center_x = int(props.centroid[1])\n",
    "\n",
    "    # Define the symmetry axes\n",
    "    angles = np.arange(0, 180, 10)\n",
    "\n",
    "    S1_scores = []\n",
    "    S2_scores = []\n",
    "\n",
    "    for angle in angles:\n",
    "        rotation_matrix = cv2.getRotationMatrix2D((center_x, center_y), angle, 1)\n",
    "        rotated_image = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "        rotated_mask = cv2.warpAffine(mask, rotation_matrix, mask.shape[::-1], flags=cv2.INTER_NEAREST)\n",
    "\n",
    "        A1 = rotated_mask[:center_y, :center_x]\n",
    "        A2 = rotated_mask[:center_y, center_x:]\n",
    "        A3 = rotated_mask[center_y:, :center_x]\n",
    "        A4 = rotated_mask[center_y:, center_x:]\n",
    "\n",
    "        # Compute the asymmetry scores\n",
    "        S1 = np.sum(np.abs(rotated_image[A1].sum() + rotated_image[A2].sum() - (rotated_image[A3].sum() + rotated_image[A4].sum())))\n",
    "        S2 = np.sum(np.abs(rotated_image[A1].sum() + rotated_image[A4].sum() - (rotated_image[A2].sum() + rotated_image[A3].sum())))\n",
    "\n",
    "        # Divide by the area of the binary mask\n",
    "        S1 /= np.sum(mask > 0)\n",
    "        S2 /= np.sum(mask > 0)\n",
    "\n",
    "        S1_scores.append(S1)\n",
    "        S2_scores.append(S2)\n",
    "\n",
    "    # The proposed asymmetry of shape features (f1, f2)\n",
    "    f1 = np.min(S1_scores)\n",
    "    f2 = np.min(S2_scores)\n",
    "\n",
    "    return f1, f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute border features\n",
    "def compute_border_features(mask):\n",
    "    # Compute the compactness of the lesion\n",
    "    props = regionprops(mask)[0]\n",
    "    perimeter = props.perimeter\n",
    "    area = props.area\n",
    "    compactness = perimeter ** 2 / (4 * np.pi * area)\n",
    "\n",
    "    # Compute the fractal dimension of the binary mask\n",
    "    fractal_dimension = 2 * np.log(perimeter) / np.log(area)\n",
    "\n",
    "    f3, f4 = compactness, fractal_dimension\n",
    "    \n",
    "    return f3, f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute color features\n",
    "def compute_color_features(image, mask):\n",
    "    # Convert RGB to CIE L*a*b* color space\n",
    "    image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "   # Reshape the image to extract pixels\n",
    "    pixels = image_lab.reshape(-1, image_lab.shape[-1])\n",
    "\n",
    "    # Randomly select 10,000 pixels from the image\n",
    "    num_pixels = 10000\n",
    "    indices = random.sample(range(pixels.shape[0]), num_pixels)\n",
    "    selected_pixels = pixels[indices]\n",
    "\n",
    "    hist, _ = np.histogramdd(selected_pixels, bins=2, range=((0, 100), (-127, 127), (-127, 127)))\n",
    "\n",
    "    # Compute the features\n",
    "    f5 = np.mean(hist)\n",
    "    f6 = np.var(hist)\n",
    "    f7 = np.sum(hist > 0) / hist.size\n",
    "\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply the mask to the HSV image\n",
    "    hsv_image = hsv_image * np.expand_dims(mask, axis=-1)\n",
    "\n",
    "    # Split the HSV image into its channels\n",
    "    h, s, v = cv2.split(hsv_image)\n",
    "\n",
    "    # Define typical hue ranges for different colors\n",
    "    white = [(0, 40), (220, 255)]\n",
    "    red = [(160, 180)]\n",
    "    light_brown = [(20, 25), (335, 360)]\n",
    "    dark_brown = [(10, 15)]\n",
    "    blue_gray = [(90, 120)]\n",
    "    black = [(0, 20)]\n",
    "\n",
    "    white_counter = 0\n",
    "    red_counter = 0\n",
    "    light_brown_counter = 0\n",
    "    dark_brown_counter = 0\n",
    "    blue_gray_counter = 0\n",
    "    black_counter = 0\n",
    "\n",
    "    # Iterate over each pixel in the hue channel\n",
    "    for row in range(h.shape[0]):\n",
    "        for col in range(h.shape[1]):\n",
    "            hue = h[row, col]\n",
    "            for color_range in [white, red, light_brown, dark_brown, blue_gray, black]:\n",
    "                for range_ in color_range:\n",
    "                    if range_[0] <= hue <= range_[1]:\n",
    "                        if color_range == white:\n",
    "                            white_counter += 1\n",
    "                        elif color_range == red:\n",
    "                            red_counter += 1\n",
    "                        elif color_range == light_brown:\n",
    "                            light_brown_counter += 1\n",
    "                        elif color_range == dark_brown:\n",
    "                            dark_brown_counter += 1\n",
    "                        elif color_range == blue_gray:\n",
    "                            blue_gray_counter += 1\n",
    "                        elif color_range == black:\n",
    "                            black_counter += 1\n",
    "\n",
    "    f8, f9, f10, f11, f12, f13 = white_counter, red_counter, light_brown_counter, dark_brown_counter, blue_gray_counter, black_counter\n",
    "    \n",
    "    return f5, f6, f7, f8, f9, f10, f11, f12, f13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute geometric features\n",
    "def compute_geometric_features(image, mask):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply binary thresholds at different percentiles\n",
    "    thresholds = [np.percentile(gray_image[mask > 0], p) for p in [25, 50, 75]]\n",
    "    binary_masks = (gray_image > thresholds[0]), (gray_image > thresholds[1]), (gray_image > thresholds[2])\n",
    "    \n",
    "    # Perform morphological opening to reduce noise\n",
    "    disk = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    opened_masks = [cv2.morphologyEx(mask, cv2.MORPH_OPEN, disk) & binary_mask for binary_mask in binary_masks]\n",
    "    \n",
    "    # Count the number of connected components (lesion pieces) in each mask\n",
    "    f14, f15, f16 = [np.max(ndi.label(mask)[1]) for mask in opened_masks]\n",
    "\n",
    "    return f14, f15, f16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute diameter feature\n",
    "def compute_diameter_feature(mask):\n",
    "    # Compute the diameter of the lesion\n",
    "    props = regionprops(mask)[0]\n",
    "    f17 = props.equivalent_diameter\n",
    "\n",
    "    return f17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(image, mask):\n",
    "    # Compute asymmetry features\n",
    "    #f1, f2 = compute_asymmetry_features(image, mask)\n",
    "    \n",
    "    # Compute border features\n",
    "    f3, f4 = compute_border_features(image, mask)\n",
    "    \n",
    "    # Compute color features\n",
    "    f5, f6, f7, f8, f9, f10, f11, f12, f13 = compute_color_features(image, mask)\n",
    "    \n",
    "    # Compute geometric features\n",
    "    f14, f15, f16 = compute_geometric_features(image, mask)\n",
    "    \n",
    "    # Compute diameter feature\n",
    "    f17 = compute_diameter_feature(mask)\n",
    "    \n",
    "    # Concatenate all features\n",
    "    features = np.array([f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15, f16, f17])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./ima205-challenge-2024/metadataTrain.csv')\n",
    "y_train = df['CLASS'].values\n",
    "#class_names = [\"Melanoma\", \"Melanocytic nevus\", \"Basal cell carcinoma\", \"Actinic keratosis\", \"Benign keratosis\", \"Dermatofibroma\", \"Vascular lesion\", \"Squamous cell carcinoma\"]\n",
    "X_train = np.zeros((len(df), 15))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    image = cv2.imread('./ima205-challenge-2024/Train/Train/' + df['ID'][i] + '.jpg')\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    mask = cv2.imread('./ima205-challenge-2024/Train/Train/' + df['ID'][i] + '_seg.png', cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (224, 224))\n",
    "    if mask is None:\n",
    "        mask = skin_lesion_segmentation('./ima205-challenge-2024/Test/Test/' + df['ID'][i] + '.jpg')\n",
    "        mask = cv2.resize(mask, (224, 224))\n",
    "    mask = mask.astype(np.uint8)\n",
    "    features = compute_features(image, mask)\n",
    "    X_train[i] = features\n",
    "    print(f'Processed image {i+1}/{len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./ima205-challenge-2024/metadataTest.csv')\n",
    "X_test = np.zeros((len(df), 15))\n",
    "for i in range(len(df)):\n",
    "    image = cv2.imread('./ima205-challenge-2024/Test/Test/' + df['ID'][i] + '.jpg')\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    mask = cv2.imread('./ima205-challenge-2024/Test/Test/' + df['ID'][i] + '_seg.png', cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.resize(mask, (224, 224))\n",
    "    if mask is None:\n",
    "        mask = skin_lesion_segmentation('./ima205-challenge-2024/Test/Test/' + df['ID'][i] + '.jpg')\n",
    "        mask = cv2.resize(mask, (224, 224))\n",
    "    mask = mask.astype(np.uint8)\n",
    "    features = compute_features(image, mask)\n",
    "    X_test[i] = features\n",
    "    print(f'Processed image {i+1}/{len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-used code\n",
    "\n",
    "# Feature Selection with RELIEF Algorithm\n",
    "def select_features(data, labels):\n",
    "    # Apply RELIEF algorithm for feature selection\n",
    "    selector = SelectKBest(score_func=ReliefF, k=10)\n",
    "    selected_features = selector.fit_transform(data, labels)\n",
    "    return selected_features\n",
    "\n",
    "# Dimensionality Reduction with Linear PCA\n",
    "def reduce_dimensionality(data, n_components):\n",
    "    # Apply linear PCA for dimensionality reduction\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_data = pca.fit_transform(data)\n",
    "    return reduced_data\n",
    "\n",
    "# Asymmetry features\n",
    "\"\"\"\n",
    "def compute_asymmetry_features_unused(image, mask):\n",
    "    # Find the center of mass of the lesion\n",
    "    props = regionprops(mask)[0]\n",
    "    center_y = int(props.centroid[0])\n",
    "    center_x = int(props.centroid[1])\n",
    "\n",
    "    # Define the symmetry axes\n",
    "    angles = np.arange(0, 180, 10)\n",
    "\n",
    "    # Initialize lists to store asymmetry scores\n",
    "    S1_scores = []\n",
    "    S2_scores = []\n",
    "    C1_scores = []\n",
    "    C2_scores = []\n",
    "\n",
    "    for angle in angles:\n",
    "        # Rotate the image and mask\n",
    "        rotation_matrix = cv2.getRotationMatrix2D((center_x, center_y), angle, 1)\n",
    "        rotated_image = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "        rotated_mask = cv2.warpAffine(mask, rotation_matrix, mask.shape[::-1], flags=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Define the regions A1, A2, A3, and A4\n",
    "        A1 = rotated_mask[:center_y, :center_x]\n",
    "        A2 = rotated_mask[:center_y, center_x:]\n",
    "        A3 = rotated_mask[center_y:, :center_x]\n",
    "        A4 = rotated_mask[center_y:, center_x:]\n",
    "\n",
    "        # Compute the asymmetry scores\n",
    "        S1 = np.sum(np.abs(rotated_image[A1].sum() + rotated_image[A2].sum() - (rotated_image[A3].sum() + rotated_image[A4].sum())))\n",
    "        S2 = np.sum(np.abs(rotated_image[A1].sum() + rotated_image[A4].sum() - (rotated_image[A2].sum() + rotated_image[A3].sum())))\n",
    "\n",
    "        # Divide by the area of the binary mask\n",
    "        S1 /= np.sum(mask > 0)\n",
    "        S2 /= np.sum(mask > 0)\n",
    "\n",
    "        S1_scores.append(S1)\n",
    "        S2_scores.append(S2)\n",
    "\n",
    "        # Combine regions for C1 and C2\n",
    "        CA1_union_A2 = np.concatenate((A1.flatten(), A2.flatten()))\n",
    "        CA3_union_A4 = np.concatenate((A3.flatten(), A4.flatten()))\n",
    "        CA1_union_A4 = np.concatenate((A1.flatten(), A4.flatten()))\n",
    "        CA2_union_A3 = np.concatenate((A2.flatten(), A3.flatten()))\n",
    "\n",
    "        # Estimate the distribution of gray-scale values using Gaussian kernel density estimation\n",
    "        kde = gaussian_kde(rotated_image.flatten())\n",
    "\n",
    "        # Compute the asymmetry scores\n",
    "        C1 = np.abs(kde.evaluate(CA1_union_A2) - kde.evaluate(CA3_union_A4)).mean()\n",
    "        C2 = np.abs(kde.evaluate(CA1_union_A4) - kde.evaluate(CA2_union_A3)).mean()\n",
    "\n",
    "        C1_scores.append(C1)\n",
    "        C2_scores.append(C2)\n",
    "\n",
    "    # The proposed asymmetry of shape features (f1, f2)\n",
    "    f1 = np.min(S1_scores)\n",
    "    f2 = np.min(S2_scores)\n",
    "\n",
    "    # The proposed asymmetry of gray-scale features (f3, f4)\n",
    "    f3 = np.min(C1_scores)\n",
    "    f4 = np.min(C2_scores)\n",
    "\n",
    "    # Calculate the radius of a circle with the same area as the lesion\n",
    "    lesion_area = np.sum(mask > 0)\n",
    "    equivalent_radius = np.sqrt(lesion_area / np.pi)\n",
    "    n_distances = []\n",
    "\n",
    "    # Generate alternative binary masks by applying thresholds at different percentiles\n",
    "    thresholds = np.arange(0.1, 1, 0.1)\n",
    "    for threshold in thresholds:\n",
    "        thresholded_mask = (image > np.percentile(image[mask > 0], threshold * 100)) & mask\n",
    "        xt, yt = regionprops(thresholded_mask)[0].centroid\n",
    "        n_distances.append(np.linalg.norm([xt - center_x, yt - center_y]) / equivalent_radius)\n",
    "\n",
    "    f5 = np.mean(n_distances)\n",
    "    f6 = np.std(n_distances)\n",
    "\n",
    "    return f1, f2, f3, f4, f5, f6\n",
    "\"\"\"\n",
    "\n",
    "# Border features\n",
    "\"\"\"\n",
    "def compute_border_features_unused(image, mask):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    border_pixels = mask ^ cv2.erode(mask, np.ones((3, 3), np.uint8))\n",
    "    \n",
    "    Rk_values = []\n",
    "    \n",
    "    # Sliding window around the border\n",
    "    window_size = 61\n",
    "    half_window = window_size // 2\n",
    "    \n",
    "    # Loop through each border pixel\n",
    "    for k, (row, col) in enumerate(zip(*np.where(border_pixels == 1))):\n",
    "        # Define the region around the border pixel\n",
    "        roi = gray_image[row - half_window:row + half_window + 1, col - half_window:col + half_window + 1]\n",
    "        \n",
    "        # Extract pixels inside and outside the lesion\n",
    "        X1 = roi[mask[row - half_window:row + half_window + 1, col - half_window:col + half_window + 1]]\n",
    "        X2 = roi[~mask[row - half_window:row + half_window + 1, col - half_window:col + half_window + 1]]\n",
    "        \n",
    "        X1_mean = np.mean(X1)\n",
    "        X2_mean = np.mean(X2)\n",
    "        X_mean = np.mean(np.concatenate((X1, X2)))\n",
    "        \n",
    "        SST = np.sum((X1 - X_mean) ** 2) + np.sum((X2 - X_mean) ** 2)\n",
    "        SSE = np.sum((X1 - X1_mean) ** 2) + np.sum((X2 - X2_mean) ** 2)\n",
    "        Rk = SSE / SST\n",
    "        Rk_values.append(Rk)\n",
    "    \n",
    "    f7 = np.percentile(Rk_values, 25)\n",
    "    f8 = np.percentile(Rk_values, 50)\n",
    "    f9 = np.percentile(Rk_values, 75)\n",
    "    \n",
    "    return f7, f8, f9\n",
    "\"\"\"\n",
    "\n",
    "# Color features\n",
    "\"\"\"\n",
    "# Convert RGB to CIE L*a*b* color space\n",
    "image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# Reshape the image to extract pixels\n",
    "pixels = image_lab.reshape(-1, image_lab.shape[-1])\n",
    "\n",
    "# Randomly select 10,000 pixels from the image\n",
    "num_pixels = 10000\n",
    "indices = random.sample(range(pixels.shape[0]), num_pixels)\n",
    "selected_pixels = pixels[indices]\n",
    "\n",
    "# Compute the 3D histogram with bin size n=2 The bin size is set to n = 2. Only the non-empty bins are considered for the score computation. We use the average number of samples in each bin (f10), the variance (f11),\n",
    "# and the percentage of non-empty bins in the color space (f12). The L component values range from 0 to 100, while the a and b components vary between âˆ’127 and 127.\n",
    "hist, _ = np.histogramdd(selected_pixels, bins=2, range=((0, 100), (-127, 127), (-127, 127)))\n",
    "\n",
    "# Compute the features\n",
    "f10 = np.mean(hist)\n",
    "f11 = np.var(hist)\n",
    "f12 = np.sum(hist > 0) / hist.size\n",
    "\n",
    "\n",
    "# Divide the lesion area into inner and outer parts\n",
    "inner_border = mask.copy()\n",
    "iteration = 0\n",
    "while np.sum(inner_border) / np.sum(mask) > 0.3:\n",
    "    inner_border = zoom(inner_border, (1 - 0.05 * iteration, 1 - 0.05 * iteration, 1), order=0)\n",
    "    iteration += 1\n",
    "\n",
    "inner_mask = (mask * inner_border).astype(bool)\n",
    "outer_mask = mask ^ inner_mask\n",
    "\n",
    "# Compute the mean L*a*b* values for inner and outer parts\n",
    "inner_lab = image_lab[inner_mask]\n",
    "outer_lab = image_lab[outer_mask]\n",
    "\n",
    "mean_inner_lab = np.mean(inner_lab, axis=0)\n",
    "mean_outer_lab = np.mean(outer_lab, axis=0)\n",
    "\n",
    "f13 = mean_inner_lab[0] - mean_outer_lab[0]\n",
    "f14 = mean_inner_lab[1] - mean_outer_lab[1]\n",
    "f15 = mean_inner_lab[2] - mean_outer_lab[2]\n",
    "\n",
    "# Compute the probability density estimate of L*a*b* channels\n",
    "kde_inner_lab = gaussian_kde(inner_lab.T)\n",
    "kde_outer_lab = gaussian_kde(outer_lab.T)\n",
    "\n",
    "# Compute the overlapping area of the densities for L*a*b* channels\n",
    "f16 = np.abs(kde_inner_lab(mean_inner_lab) - kde_outer_lab(mean_inner_lab))\n",
    "f17 = np.abs(kde_inner_lab(mean_inner_lab[0], mean_inner_lab[1]) - kde_outer_lab(mean_inner_lab[0], mean_inner_lab[1]))\n",
    "f18 = np.abs(kde_inner_lab(mean_inner_lab[0], mean_inner_lab[2]) - kde_outer_lab(mean_inner_lab[0], mean_inner_lab[2]))\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape(-1, 1, 15, 1)\n",
    "X_test = np.array(X_test).reshape(-1, 1, 15, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(1, 15, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=16, epochs=5, sample_weight=class_weights, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Print the predicted labels\n",
    "print(\"Predicted labels:\", predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "csv = pd.DataFrame({'ID': df['ID'], 'CLASS': predicted_labels})\n",
    "csv.to_csv('sub1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
